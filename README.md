<div align="center">

# SawSing - Subtractive DDSP Vocoder for singing voice <!-- omit in toc -->
[![ColabBadge]][notebook]
[![PaperBadge]][paper]  

</div>

Clone of ***SawSing*** DDSP vocoder's official Implementation.  

<!-- Auto-generated by "Markdown All in One" extension -->
- [Demo](#demo)
- [Usage](#usage)
  - [Install](#install)
  - [Train](#train)
  - [Inference](#inference)
- [Results](#results)
- [References](#references)

## Demo
[demo page].  

## Usage
### Install

```bash
# pip install "torch==1.11.0" -q      # Based on your environment (validated with vX.YZ)
# pip install "torchaudio==0.11.0" -q # Based on your environment
# pip install git+https://github.com/tarepan/SawSing-official
pip install -r requirements.txt 
```

### Train
Jump to ☞ [![ColabBadge]][notebook], then Run. That's all!  

For arguments, check [./sawsing/config.py](https://github.com/tarepan/SawSing-official/blob/main/sawsing/config.py).  
For dataset, check [`speechcorpusy`](https://github.com/tarepan/speechcorpusy).  

Please refer to [dataset.md](./docs/dataset.md) for more details.

Train vocoders from scratch. 
1. Modify the configuration file `..config/<model_name>.yaml`
2. Run the following command:
```bash
python main.py --config ./configs/sawsinsub.yaml \
               --stage  training \
               --model SawSinSub
```

You can specify the model with `--model` argument.  
Currently this repository support 5 ***harmonic plus noise*** vocoders[4] (3 in the paper, 2 not):

| Model Name (in the paper) | Harmonics Synthesizer                        | Note                        |
|:-------------------------:|:--------------------------------------------:|:---------------------------:|
| `SawSub`                  | Subtracted       Sawtooth (exact)            | modified from SawSing paper |
| `SawSinSub` (SawSing)     | Subtracted       Sawtooth (additive approx.) | from SawSing paper          |
| `Sins`      (DDSP-Add)    |            Added sinusoids                   | from DDSP paper             |
| `Full`                    | Subtracted Added sinusoids                   | modified from DDSP paper    |
| `DWS`       (DWTS)        | Wavetable                                    | [3]                         |


`SawSinSub` differ from `SawSub` in that it approximate Sawtooth with band-limited addtive sinusoids. This works as anti-aliasing.  
More details of syntehsizers, refet to [synthesizer_demo](./synth_demo.ipynb).  

[3] (ICASSP'22)[Differentiable Wavetable Synthesis](https://arxiv.org/abs/2111.10003)  
[4] (ICASSP'93) [HNS: Speech modification based on a harmonic+noise model](https://ieeexplore.ieee.org/document/319365)  

For validation (compute validation loss and real-time factor):

1. Modify the configuration file  `..config/<model_name>.yaml`
2. Run the following command:

```bash
# SawSing as an example
python main.py --config ./configs/sawsinsub.yaml  \
              --stage validation \
              --model SawSinSub \
              --model_ckpt ./exp/f1-full/sawsinsub-256/ckpts/vocoder_27740_70.0_params.pt \
              --output_dir ./test_gen
```

### Inference
Both CLI and Python supported.  
For detail, jump to ☞ [![ColabBadge]][notebook] and check it.  

mel-to-wave inference.  
The code and specfication for extracting mel-spectrograms can be found in [`preprocess.py`](./preprocess.py).  

```bash
# SawSing as an example
python main.py --config ./configs/sawsinsub.yaml  \
              --stage inference \
              --model SawSinSub \
              --model_ckpt ./exp/f1-full/sawsinsub-256/ckpts/vocoder_27740_70.0_params.pt \
              --input_dir  ./path/to/mel
              --output_dir ./test_gen
```

For Sawsing buzzing artifacts, run post-processing.  
For more details, please refer to [here](./postprocessing/).

## Results
### Sample <!-- omit in toc -->
[Demo](#demo)

### Performance <!-- omit in toc -->
- training
  - x.x [iter/sec] @ NVIDIA X0 on Google Colaboratory (AMP+)
  - take about y days for whole training
  - Original authors use Nvidia RTX 3090 Ti GPU x1
- inference
  - z.z [sec/sample] @ xx

### Pre-trained Models & records
The authors provide checkpoints and experiment records. Great!  

* Checkpoints
  * **Sins (DDSP-Add)**:  [`./exp/f1-full/sins/ckpts/`](./exp/f1-full/sins/ckpts/)
  * **SawSinSub (Sawsing)**:  [`./exp/f1-full/sawsinsub-256/ckpts/`](./exp/f1-full/sawsinsub-256/ckpts/)
* The full experimental records, reports and checkpoints can be found under the [`exp`](./exp/) folder.

## Dicsussion and Future Work
- glitch artifacts: see also [5]
- buzzing artifacts
  - only in subtractive synthesizers (SawSub, SawSinSub, Full), see also [6]
  - possible solutions
    - Replace LTV-FIR with better filter
    - Applying UV mask
- E2E training: data-efficient, intepretable and lightweight -> Joint training with acoustic models
- Feature: mel-spectrograms -> controlable features, e.g. f0, UV mask

[5] (ICASSP'22) [Improving adversarial waveform generation based singing voice conversion with harmonic signals](https://arxiv.org/abs/2201.10130)  
[6] (INTERSPEECH'22) [Unified Source-Filter GAN with Harmonic-plus-Noise Source Excitation Generation](https://arxiv.org/pdf/2205.06053.pdf)

## References
### Original paper <!-- omit in toc -->
[![PaperBadge]][paper]  
```
@article{sawsing,
  title={DDSP-based Singing Vocoders: A New Subtractive-based Synthesizer and A Comprehensive Evaluation},
  author={Da-Yi Wu, Wen-Yi Hsiao, Fu-Rong Yang, Oscar Friedman, Warren Jackson, Scott Bruzenak, Yi-Wen Liu, Yi-Hsuan Yang},
  journal = {Proc. International Society for Music Information Retrieval},
  year    = {2022},
}
```

### Acknowlegements <!-- omit in toc -->
- Any preceding works

[ColabBadge]:https://colab.research.google.com/assets/colab-badge.svg

[paper]:https://arxiv.org/abs/2208.04756
[PaperBadge]:https://img.shields.io/badge/paper-arxiv.2208.04756-B31B1B.svg
[notebook]:https://colab.research.google.com/github/tarepan/SawSing-official/blob/main/sawsing.ipynb
[demo page]:https://ddspvocoder.github.io/ismir-demo/